rule mpileup:
    input:
        bam="data/alignments/sets/{aligner}~{ref}~{sampleset}.bam",
        bai="data/alignments/sets/{aligner}~{ref}~{sampleset}.bam.bai",
        sset="data/samplelists/{sampleset}.txt",
        ref=lambda wc: config['refs'][wc.ref],
    output:
        bcf="data/variants/raw_split/mpileup~{aligner}~{ref}~{sampleset}/{region}.bcf",
    log:
        "data/log/mpileup/{aligner}~{ref}~{sampleset}/{region}.log"
    benchmark:
        "data/log/mpileup/{aligner}~{ref}~{sampleset}/{region}.benchmark"
    params:
        theta=lambda wc: config["varcall"]["samplesets"][wc.sampleset].get("theta_prior", 0.01),
        minmq=lambda wc: config["varcall"]["minmapq"].get(wc.aligner, 5),
        minbq=config["varcall"]["minbq"],
    priority: 1  # get them done earlier, normalisation is super quick
    threads: 2
    shell:
        "( bcftools mpileup"
        "   --redo-BAQ"
        "   --max-depth 100000" # the default per file max (250x) is insane, i.e. <1x for most sets. new limit of 20000x  equates to a max. of 20x across all samples.
        "   --min-MQ {params.minmq}"
        "   --min-BQ {params.minbq}"
        "   --fasta-ref {input.ref}"
        "   --samples-file {input.sset}"
        "   --annotate FORMAT/DP,FORMAT/AD,FORMAT/SP,INFO/AD" #output extra tags
        "   --region '{wildcards.region}'"
        "   --output-type u" # uncompressed bam
        "   {input.bam}"
        " | bcftools call"
        "   --threads {threads}"
        "   --targets '{wildcards.region}'" # might not be needed
        "   --multiallelic-caller"
        "   --prior {params.theta}"
        "   -O b" # compressed bam
        "   -o {output.bcf}"
        " ) >{log} 2>&1"


