@article{beber23_taxpastataxonomic,
  title = {{{TAXPASTA}}: {{TAXonomic Profile Aggregation}} and {{STAndardisation}}},
  shorttitle = {{{TAXPASTA}}},
  author = {Beber, Moritz E. and Borry, Maxime and Stamouli, Sofia and Yates, James A. Fellows},
  date = {2023-07-11},
  journaltitle = {Journal of Open Source Software},
  volume = {8},
  number = {87},
  pages = {5627},
  issn = {2475-9066},
  doi = {10.21105/joss.05627},
  url = {https://joss.theoj.org/papers/10.21105/joss.05627},
  urldate = {2023-10-04},
  abstract = {Beber et al., (2023). TAXPASTA: TAXonomic Profile Aggregation and STAndardisation. Journal of Open Source Software, 8(87), 5627, https://doi.org/10.21105/joss.05627},
  langid = {english},
  file = {/home/kevin/work/bibliography/pdfs/beber23_taxpastataxonomic__journal_of_open_source_software__taxpasta.pdf}
}

@article{buchfink15_fastsensitive,
  title = {Fast and Sensitive Protein Alignment Using {{DIAMOND}}},
  author = {Buchfink, Benjamin and Xie, Chao and Huson, Daniel H.},
  date = {2015-01},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Meth},
  volume = {12},
  number = {1},
  pages = {59--60},
  issn = {1548-7091},
  doi = {10.1038/nmeth.3176},
  url = {http://www.nature.com/nmeth/journal/v12/n1/full/nmeth.3176.html},
  urldate = {2016-07-13},
  abstract = {The alignment of sequencing reads against a protein reference database is a major computational bottleneck in metagenomics and data-intensive evolutionary projects. Although recent tools offer improved performance over the gold standard BLASTX, they exhibit only a modest speedup or low sensitivity. We introduce DIAMOND, an open-source algorithm based on double indexing that is 20,000 times faster than BLASTX on short reads and has a similar degree of sensitivity.},
  langid = {english},
  keywords = {Software},
  file = {/home/kevin/work/bibliography/pdfs/buchfink15_fast__nature_methods__fast_and_sensitive_protein_alignment_using_diamond.pdf}
}

@article{danecek21_twelveyears,
  title = {Twelve Years of {{SAMtools}} and {{BCFtools}}},
  author = {Danecek, Petr and Bonfield, James K. and Liddle, Jennifer and Marshall, John and Ohan, Valeriu and Pollard, Martin O. and Whitwham, Andrew and Keane, Thomas and McCarthy, Shane A. and Davies, Robert M. and Li, Heng},
  date = {2021-02-16},
  journaltitle = {GigaScience},
  shortjournal = {Gigascience},
  volume = {10},
  number = {2},
  eprint = {33590861},
  eprinttype = {pmid},
  pages = {giab008},
  issn = {2047-217X},
  doi = {10.1093/gigascience/giab008},
  abstract = {BACKGROUND: SAMtools and BCFtools are widely used programs for processing and analysing high-throughput sequencing data. They include tools for file format conversion and manipulation, sorting, querying, statistics, variant calling, and effect analysis amongst other methods. FINDINGS: The first version appeared online 12 years ago and has been maintained and further developed ever since, with many new features and improvements added over the years. The SAMtools and BCFtools packages represent a unique collection of tools that have been used in numerous other software projects and countless genomic pipelines. CONCLUSION: Both SAMtools and BCFtools are freely available on GitHub under the permissive MIT licence, free for both non-commercial and commercial use. Both packages have been installed {$>$}1 million times via Bioconda. The source code and documentation are available from https://www.htslib.org.},
  langid = {english},
  pmcid = {PMC7931819},
  keywords = {bcftools,data analysis,Genome,Genomics,High-Throughput Nucleotide Sequencing,high-throughput sequencing,next generation sequencing,samtools,Software,variant calling},
  file = {/home/kevin/work/bibliography/pdfs/danecek21_twelveyears__gigascience__twelve_years_of_samtools_and_bcftools.pdf}
}

@article{ewels16_multiqcsummarize,
  title = {{{MultiQC}}: Summarize Analysis Results for Multiple Tools and Samples in a Single Report},
  shorttitle = {{{MultiQC}}},
  author = {Ewels, Philip and Magnusson, Måns and Lundin, Sverker and Käller, Max},
  date = {2016-10-01},
  journaltitle = {Bioinformatics (Oxford, England)},
  shortjournal = {Bioinformatics},
  volume = {32},
  number = {19},
  eprint = {27312411},
  eprinttype = {pmid},
  pages = {3047--3048},
  issn = {1367-4811},
  doi = {10.1093/bioinformatics/btw354},
  abstract = {MOTIVATION: Fast and accurate quality control is essential for studies involving next-generation sequencing data. Whilst numerous tools exist to quantify QC metrics, there is no common approach to flexibly integrate these across tools and large sample sets. Assessing analysis results across an entire project can be time consuming and error prone; batch effects and outlier samples can easily be missed in the early stages of analysis. RESULTS: We present MultiQC, a tool to create a single report visualising output from multiple tools across many samples, enabling global trends and biases to be quickly identified. MultiQC can plot data from many common bioinformatics tools and is built to allow easy extension and customization. AVAILABILITY AND IMPLEMENTATION: MultiQC is available with an GNU GPLv3 license on GitHub, the Python Package Index and Bioconda. Documentation and example reports are available at http://multiqc.info CONTACT: phil.ewels@scilifelab.se.},
  langid = {english},
  pmcid = {PMC5039924},
  keywords = {Computational Biology,High-Throughput Nucleotide Sequencing,Quality Control,Software},
  file = {/home/kevin/work/bibliography/pdfs/ewels16_multiqcsummarize__bioinformatics_(oxford,_england)__multiqc.pdf;/home/kevin/work/bibliography/pdfs/ewels16_multiqcsummarize__bioinformatics_(oxford,_england)__multiqc2.pdf}
}

@online{hanson23_strainscientific,
  title = {The Strain on Scientific Publishing},
  author = {Hanson, Mark A. and Barreiro, Pablo Gómez and Crosetto, Paolo and Brockington, Dan},
  date = {2023-09-27},
  eprint = {2309.15884},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2309.15884},
  url = {http://arxiv.org/abs/2309.15884},
  urldate = {2023-10-05},
  abstract = {Scientists are increasingly overwhelmed by the volume of articles being published. Total articles indexed in Scopus and Web of Science have grown exponentially in recent years; in 2022 the article total was 47\% higher than in 2016, which has outpaced the limited growth, if any, in the number of practising scientists. Thus, publication workload per scientist (writing, reviewing, editing) has increased dramatically. We define this problem as the strain on scientific publishing. To analyse this strain, we present five data-driven metrics showing publisher growth, processing times, and citation behaviours. We draw these data from web scrapes, requests for data from publishers, and material that is freely available through publisher websites. Our findings are based on millions of papers produced by leading academic publishers. We find specific groups have disproportionately grown in their articles published per year, contributing to this strain. Some publishers enabled this growth by adopting a strategy of hosting special issues, which publish articles with reduced turnaround times. Given pressures on researchers to publish or perish to be competitive for funding applications, this strain was likely amplified by these offers to publish more articles. We also observed widespread year-over-year inflation of journal impact factors coinciding with this strain, which risks confusing quality signals. Such exponential growth cannot be sustained. The metrics we define here should enable this evolving conversation to reach actionable solutions to address the strain on scientific publishing.},
  pubstate = {preprint},
  keywords = {Computer Science - Digital Libraries},
  file = {/home/kevin/work/bibliography/pdfs/hanson23_strainscientific____the_strain_on_scientific_publishing.pdf}
}

@article{kim16_centrifugerapid,
  title = {Centrifuge: Rapid and Sensitive Classification of Metagenomic Sequences},
  shorttitle = {Centrifuge},
  author = {Kim, Daehwan and Song, Li and Breitwieser, Florian P. and Salzberg, Steven L.},
  date = {2016-10-17},
  journaltitle = {Genome Research},
  shortjournal = {Genome Res.},
  eprint = {27852649},
  eprinttype = {pmid},
  publisher = {{Cold Spring Harbor Lab}},
  issn = {1088-9051, 1549-5469},
  doi = {10.1101/gr.210641.116},
  url = {https://genome.cshlp.org/content/early/2016/11/16/gr.210641.116},
  urldate = {2023-10-04},
  abstract = {Centrifuge is a novel microbial classification engine that enables rapid, accurate, and sensitive labeling of reads and quantification of species on desktop computers. The system uses an indexing scheme based on the Burrows-Wheeler transform (BWT) and the Ferragina-Manzini (FM) index, optimized specifically for the metagenomic classification problem. Centrifuge requires a relatively small index (4.2 GB for 4078 bacterial and 200 archaeal genomes) and classifies sequences at very high speed, allowing it to process the millions of reads from a typical high-throughput DNA sequencing run within a few minutes. Together, these advances enable timely and accurate analysis of large metagenomics data sets on conventional desktop computers. Because of its space-optimized indexing schemes, Centrifuge also makes it possible to index the entire NCBI nonredundant nucleotide sequence database (a total of 109 billion bases) with an index size of 69 GB, in contrast to k-mer-based indexing schemes, which require far more extensive space.},
  langid = {english},
  file = {/home/kevin/work/bibliography/pdfs/kim16_centrifugerapid__genome_research__centrifuge.pdf;/home/kevin/work/bibliography/pdfs/kim16_centrifugerapid__genome_research__centrifuge2.pdf}
}

@article{koster12_snakemakescalable,
  title = {Snakemake --- a Scalable Bioinformatics Workflow Engine},
  author = {Köster, Johannes and Rahmann, Sven},
  date = {2012-01-10},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {28},
  number = {19},
  eprint = {22908215},
  eprinttype = {pmid},
  pages = {2520--2522},
  issn = {1367-4803, 1460-2059},
  doi = {10.1093/bioinformatics/bts480},
  url = {http://bioinformatics.oxfordjournals.org/content/28/19/2520},
  urldate = {2016-03-30},
  abstract = {Summary: Snakemake is a workflow engine that provides a readable Python-based workflow definition language and a powerful execution environment that scales from single-core workstations to compute clusters without modifying the workflow. It is the first system to support the use of automatically inferred multiple named wildcards (or variables) in input and output filenames. Availability: http://snakemake.googlecode.com. Contact: johannes.koester@uni-due.de},
  langid = {english},
  file = {/home/kevin/work/bibliography/pdfs/koster12_snakemake__bioinformatics__snakemake_---_a_scalable_bioinformatics_workflow_engine.pdf}
}

@article{koster21_snakemakeworkflows,
  title = {Snakemake-Workflows/Dna-Seq-Gatk-Variant-Calling},
  shorttitle = {Snakemake-Workflows/Dna-Seq-Gatk-Variant-Calling},
  author = {Köster, Johannes and {Micwessolly} and Kuthe, Elias and De Coster, Wouter},
  date = {2021-05-02},
  doi = {10.5281/ZENODO.4677629},
  url = {https://zenodo.org/record/4677629},
  urldate = {2023-10-09},
  abstract = {Formatting according to best practices (snakefmt).}
}

@article{li09_sequencealignment,
  title = {The {{Sequence Alignment}}/{{Map}} Format and {{SAMtools}}},
  author = {Li, Heng and Handsaker, Bob and Wysoker, Alec and Fennell, Tim and Ruan, Jue and Homer, Nils and Marth, Gabor and Abecasis, Goncalo and Durbin, Richard and {1000 Genome Project Data Processing Subgroup}},
  date = {2009-08-15},
  journaltitle = {Bioinformatics (Oxford, England)},
  shortjournal = {Bioinformatics},
  volume = {25},
  number = {16},
  eprint = {19505943},
  eprinttype = {pmid},
  pages = {2078--2079},
  issn = {1367-4811},
  doi = {10.1093/bioinformatics/btp352},
  abstract = {SUMMARY: The Sequence Alignment/Map (SAM) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms. It is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 Genomes Project are released. SAMtools implements various utilities for post-processing alignments in the SAM format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments. AVAILABILITY: http://samtools.sourceforge.net.},
  langid = {english},
  pmcid = {PMC2723002},
  keywords = {Algorithms,Base Sequence,Computational Biology,Genome,Genomics,Molecular Sequence Data,Sequence Alignment,{Sequence Analysis, DNA},Software},
  file = {/home/kevin/work/bibliography/pdfs/li09_sequencealignment__bioinformatics_(oxford,_england)__the_sequence_alignment-map_format_and_samtools.pdf;/home/kevin/work/bibliography/pdfs/li09_sequencealignment__bioinformatics_(oxford,_england)__the_sequence_alignment-map_format_and_samtools2.pdf}
}

@article{li11_statisticalframework,
  title = {A Statistical Framework for {{SNP}} Calling, Mutation Discovery, Association Mapping and Population Genetical Parameter Estimation from Sequencing Data},
  author = {Li, Heng},
  date = {2011-11-01},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {27},
  number = {21},
  eprint = {21903627},
  eprinttype = {pmid},
  pages = {2987--2993},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btr509},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3198575/},
  urldate = {2017-05-30},
  abstract = {Motivation: Most existing methods for DNA sequence analysis rely on accurate sequences or genotypes. However, in applications of the next-generation sequencing (NGS), accurate genotypes may not be easily obtained (e.g. multi-sample low-coverage sequencing or somatic mutation discovery). These applications press for the development of new methods for analyzing sequence data with uncertainty., Results: We present a statistical framework for calling SNPs, discovering somatic mutations, inferring population genetical parameters and performing association tests directly based on sequencing data without explicit genotyping or linkage-based imputation. On real data, we demonstrate that our method achieves comparable accuracy to alternative methods for estimating site allele count, for inferring allele frequency spectrum and for association mapping. We also highlight the necessity of using symmetric datasets for finding somatic mutations and confirm that for discovering rare events, mismapping is frequently the leading source of errors., Availability: http://samtools.sourceforge.net, Contact: hengli@broadinstitute.org},
  pmcid = {PMC3198575},
  file = {/home/kevin/work/bibliography/pdfs/li11_statistical__bioinformatics__a_statistical_framework_for_snp_calling,_mutation_discovery,_association.pdf}
}

@article{li13_aligningsequence,
  title = {Aligning Sequence Reads, Clone Sequences and Assembly Contigs with {{BWA-MEM}}},
  author = {Li, Heng},
  date = {2013-03-16},
  url = {https://arxiv.org/abs/1303.3997v2},
  urldate = {2019-01-02},
  abstract = {Summary: BWA-MEM is a new alignment algorithm for aligning sequence reads or long query sequences against a large reference genome such as human. It automatically chooses between local and end-to-end alignments, supports paired-end reads and performs chimeric alignment. The algorithm is robust to sequencing errors and applicable to a wide range of sequence lengths from 70bp to a few megabases. For mapping 100bp sequences, BWA-MEM shows better performance than several state-of-art read aligners to date.   Availability and implementation: BWA-MEM is implemented as a component of BWA, which is available at http://github.com/lh3/bwa.   Contact: hengli@broadinstitute.org},
  langid = {english},
  file = {/home/kevin/work/bibliography/pdfs/li13_aligning____aligning_sequence_reads,_clone_sequences_and_assembly_contigs_with_bwa-mem.pdf}
}

@article{li18_minimap2pairwise,
  title = {Minimap2: Pairwise Alignment for Nucleotide Sequences},
  shorttitle = {Minimap2},
  author = {Li, Heng},
  editor = {Birol, Inanc},
  date = {2018-09-15},
  journaltitle = {Bioinformatics},
  volume = {34},
  number = {18},
  pages = {3094--3100},
  issn = {1367-4803, 1367-4811},
  doi = {10.1093/bioinformatics/bty191},
  url = {https://academic.oup.com/bioinformatics/article/34/18/3094/4994778},
  urldate = {2023-10-04},
  abstract = {Abstract                            Motivation               Recent advances in sequencing technologies promise ultra-long reads of ∼100 kb in average, full-length mRNA or cDNA reads in high throughput and genomic contigs over 100 Mb in length. Existing alignment programs are unable or inefficient to process such data at scale, which presses for the development of new alignment algorithms.                                         Results               Minimap2 is a general-purpose alignment program to map DNA or long mRNA sequences against a large reference database. It works with accurate short reads of ≥100\,bp in length, ≥1\,kb genomic reads at error rate ∼15\%, full-length noisy Direct RNA or cDNA reads and assembly contigs or closely related full chromosomes of hundreds of megabases in length. Minimap2 does split-read alignment, employs concave gap cost for long insertions and deletions and introduces new heuristics to reduce spurious alignments. It is 3–4 times as fast as mainstream short-read mappers at comparable accuracy, and is ≥30 times faster than long-read genomic or cDNA mappers at higher accuracy, surpassing most aligners specialized in one type of alignment.                                         Availability and implementation               https://github.com/lh3/minimap2                                         Supplementary information               Supplementary data are available at Bioinformatics online.},
  langid = {english},
  file = {/home/kevin/work/bibliography/pdfs/li18_minimap2pairwise__bioinformatics__minimap2.pdf}
}

@article{li21_newstrategies,
  title = {New Strategies to Improve Minimap2 Alignment Accuracy},
  author = {Li, Heng},
  editor = {Alkan, Can},
  date = {2021-12-07},
  journaltitle = {Bioinformatics},
  volume = {37},
  number = {23},
  pages = {4572--4574},
  issn = {1367-4803, 1367-4811},
  doi = {10.1093/bioinformatics/btab705},
  url = {https://academic.oup.com/bioinformatics/article/37/23/4572/6384570},
  urldate = {2023-10-04},
  abstract = {Abstract                            Summary               We present several recent improvements to minimap2, a versatile pairwise aligner for nucleotide sequences. Now minimap2 v2.22 can more accurately map long reads to highly repetitive regions and align through insertions or deletions up to 100\,kb by default, addressing major weakness in minimap2 v2.18 or earlier.                                         Availability and implementation               https://github.com/lh3/minimap2.},
  langid = {english},
  file = {/home/kevin/work/bibliography/pdfs/li21_newstrategies__bioinformatics__new_strategies_to_improve_minimap2_alignment_accuracy.pdf}
}

@article{lindgreen12_adapterremoval,
  title = {{{AdapterRemoval}}: Easy Cleaning of next-Generation Sequencing Reads},
  shorttitle = {{{AdapterRemoval}}},
  author = {Lindgreen, Stinus},
  date = {2012},
  journaltitle = {BMC Research Notes},
  shortjournal = {BMC Research Notes},
  volume = {5},
  pages = {337},
  issn = {1756-0500},
  doi = {10.1186/1756-0500-5-337},
  url = {http://dx.doi.org/10.1186/1756-0500-5-337},
  urldate = {2017-02-12},
  abstract = {With the advent of next-generation sequencing there is an increased demand for tools to pre-process and handle the vast amounts of data generated. One recurring problem is adapter contamination in the reads, i.e. the partial or complete sequencing of adapter sequences. These adapter sequences have to be removed as they can hinder correct mapping of the reads and influence SNP calling and other downstream analyses.},
  file = {/home/kevin/work/bibliography/pdfs/lindgreen12_adapterremoval__bmc_research_notes__adapterremoval.pdf}
}

@article{lu17_brackenestimating,
  title = {Bracken: Estimating Species Abundance in Metagenomics Data},
  shorttitle = {Bracken},
  author = {Lu, Jennifer and Breitwieser, Florian P. and Thielen, Peter and Salzberg, Steven L.},
  date = {2017-01-02},
  journaltitle = {PeerJ Computer Science},
  shortjournal = {PeerJ Comput. Sci.},
  volume = {3},
  pages = {e104},
  issn = {2376-5992},
  doi = {10.7717/peerj-cs.104},
  url = {https://peerj.com/articles/cs-104},
  urldate = {2017-08-08},
  abstract = {Metagenomic experiments attempt to characterize microbial communities using high-throughput DNA sequencing. Identification of the microorganisms in a sample provides information about the genetic profile, population structure, and role of microorganisms within an environment. Until recently, most metagenomics studies focused on high-level characterization at the level of phyla, or alternatively sequenced the 16S ribosomal RNA gene that is present in bacterial species. As the cost of sequencing has fallen, though, metagenomics experiments have increasingly used unbiased shotgun sequencing to capture all the organisms in a sample. This approach requires a method for estimating abundance directly from the raw read data. Here we describe a fast, accurate new method that computes the abundance at the species level using the reads collected in a metagenomics experiment. Bracken (Bayesian Reestimation of Abundance after Classification with KrakEN) uses the taxonomic assignments made by Kraken, a very fast read-level classifier, along with information about the genomes themselves to estimate abundance at the species level, the genus level, or above. We demonstrate that Bracken can produce accurate species- and genus-level abundance estimates even when a sample contains multiple near-identical species.},
  langid = {english},
  file = {/home/kevin/work/bibliography/pdfs/lu17_bracken__peerj_computer_science__bracken.pdf}
}

@article{menzel16_fastsensitive,
  title = {Fast and Sensitive Taxonomic Classification for Metagenomics with {{Kaiju}}},
  author = {Menzel, Peter and Ng, Kim Lee and Krogh, Anders},
  date = {2016-04-13},
  journaltitle = {Nature Communications},
  volume = {7},
  pages = {11257},
  issn = {2041-1723},
  doi = {10.1038/ncomms11257},
  url = {http://www.nature.com/doifinder/10.1038/ncomms11257},
  urldate = {2016-09-27},
  keywords = {Bioinformatics,Biological sciences,Genetics},
  file = {/home/kevin/work/bibliography/pdfs/menzel16_fast__nature_communications__fast_and_sensitive_taxonomic_classification_for_metagenomics_with_kaiju.pdf}
}

@article{moran15_hologenomeconcept,
  title = {The {{Hologenome Concept}}: {{Helpful}} or {{Hollow}}?},
  shorttitle = {The {{Hologenome Concept}}},
  author = {Moran, Nancy A. and Sloan, Daniel B.},
  date = {2015-12-04},
  journaltitle = {PLoS Biol},
  shortjournal = {PLoS Biol},
  volume = {13},
  number = {12},
  pages = {e1002311},
  doi = {10.1371/journal.pbio.1002311},
  url = {http://dx.doi.org/10.1371/journal.pbio.1002311},
  urldate = {2015-12-09},
  abstract = {It is accepted that microbial symbionts are important to the biology of their hosts, but this essay asks what evidence is needed to determine whether symbionts and hosts have coevolved and whether they form higher units of evolutionary selection.},
  file = {/home/kevin/work/bibliography/pdfs/moran15_hologenome__plos_biol__the_hologenome_concept.pdf}
}

@article{schubert16_adapterremoval,
  title = {{{AdapterRemoval}} v2: Rapid Adapter Trimming, Identification, and Read Merging},
  shorttitle = {{{AdapterRemoval}} V2},
  author = {Schubert, Mikkel and Lindgreen, Stinus and Orlando, Ludovic},
  date = {2016},
  journaltitle = {BMC Research Notes},
  shortjournal = {BMC Research Notes},
  volume = {9},
  pages = {88},
  issn = {1756-0500},
  doi = {10.1186/s13104-016-1900-2},
  url = {http://dx.doi.org/10.1186/s13104-016-1900-2},
  urldate = {2016-06-07},
  abstract = {As high-throughput sequencing platforms produce longer and longer reads, sequences generated from short inserts, such as those obtained from fossil and degraded material, are increasingly expected to contain adapter sequences. Efficient adapter trimming algorithms are also needed to process the growing amount of data generated per sequencing run.},
  keywords = {Adapter identification,Adapter trimming,Data pre-processing,High-throughput sequencing,Sequence Alignment},
  file = {/home/kevin/work/bibliography/pdfs/schubert16_adapterremoval__bmc_research_notes__adapterremoval_v2.pdf}
}

@article{sedlazeck13_nextgenmapfast,
  title = {{{NextGenMap}}: Fast and Accurate Read Mapping in Highly Polymorphic Genomes},
  shorttitle = {{{NextGenMap}}},
  author = {Sedlazeck, Fritz J. and Rescheneder, Philipp and Von Haeseler, Arndt},
  date = {2013-11-01},
  journaltitle = {Bioinformatics},
  volume = {29},
  number = {21},
  pages = {2790--2791},
  issn = {1367-4803, 1367-4811},
  doi = {10.1093/bioinformatics/btt468},
  url = {https://academic.oup.com/bioinformatics/article/29/21/2790/195626},
  urldate = {2023-10-04},
  abstract = {Abstract             Summary: When choosing a read mapper, one faces the trade off between speed and the ability to map reads in highly polymorphic regions. Here, we report NextGenMap, a fast and accurate read mapper, which reduces this dilemma. NextGenMap aligns reads reliably to a reference genome even when the sequence difference between target and reference genome is large, i.e. highly polymorphic genome. At the same time, NextGenMap outperforms current mapping methods with respect to runtime and to the number of correctly mapped reads. NextGenMap efficiently uses the available hardware by exploiting multi-core CPUs as well as graphic cards (GPUs), if available. In addition, NextGenMap handles automatically any read data independent of read length and sequencing technology.             Availability: NextGenMap source code and documentation are available at: http://cibiv.github.io/NextGenMap/             Contact: fritz.sedlazeck@univie.ac.at             Supplementary information: ~Supplementary data are available at Bioinformatics online.},
  langid = {english},
  file = {/home/kevin/work/bibliography/pdfs/sedlazeck13_nextgenmapfast__bioinformatics__nextgenmap.pdf}
}

@online{weigel20_pathocomproposal,
  title = {{{PATHOCOM}} Proposal},
  author = {Weigel, Detlef and Bergelson, Joy and Roux, Fabrice},
  date = {2020-11-01},
  eprinttype = {figshare},
  doi = {10.6084/m9.figshare.13174337.v1},
  url = {https://figshare.com/articles/preprint/PATHOCOM_proposal/13174337/1},
  urldate = {2023-10-04},
  abstract = {PATHOCOM is a project proposal submitted by Detlef Weigel, Fabrice Roux and Joy Bergelson to the ERC Synergy Grants (ERC-SyG) 2020 call},
  langid = {english},
  pubstate = {preprint},
  file = {/home/kevin/work/bibliography/pdfs/weigel20_pathocomproposal____pathocom_proposal.pdf}
}

@article{yates23_nfcore,
  title = {Nf-Core/Taxprofiler},
  shorttitle = {Nf-Core/Taxprofiler},
  author = {Yates, James A. Fellows and Stamouli, Sofia and Andersson-Li, Lili and Beber, Moritz E. and Mesilaakso, Lauri and {Nf-Core Bot} and Christensen, Thomas A. and {Mahwash Jamy} and {JIANHONG OU} and Stepien, Rafal and Borry, Maxime and {Husen M. Umer} and Syme, Robert and Hübner, Alex and {Zandra Fagernäs}},
  date = {2023-09-19},
  doi = {10.5281/ZENODO.7728364},
  url = {https://zenodo.org/record/7728364},
  urldate = {2023-10-09},
  abstract = {{$<$}code{$>$}Added{$<$}/code{$>$} \#298 {$<$}strong{$>$}New classifier{$<$}/strong{$>$} ganon (added by @jfy133) \#312 {$<$}strong{$>$}New classifier{$<$}/strong{$>$} KMCP (added by @sofstam) \#318 {$<$}strong{$>$}New classifier{$<$}/strong{$>$} MetaPhlAn4 (MetaPhlAn3 support remains) (added by @LilyAnderssonLee) \#276 Implemented batching in the KrakenUniq samples processing (added by @Midnighter) \#272 Add saving of final 'analysis-ready-reads' to dedicated directory (❤️ to @alexhbnr for request, added by @jfy133) \#303 Add support for taxpasta profile standardisation in single sample pipeline runs (❤️ to @artur-matysik for request, added by @jfy133) \#308 Add citations and bibliographic information to the MultiQC methods text of tools used in a given pipeline run (added by @jfy133) \#315 Updated to nf-core pipeline template v2.9 (added by @sofstam \&amp; @jfy133) \#319 Added support for virus hit expansion in Kaiju (❤️ to @dnlrxn for requesting, added by @jfy133) \#323 Add ability to skip sequencing quality control tools (❤️ to @vinisalazar for requesting, added by @jfy133) \#345 Add simple tutorial to explain how to get up and running with an nf-core/taxprofiler run (added by @jfy133) \#355 Add support for TAXPASTA's {$<$}code{$>$}--add-rank-lineage{$<$}/code{$>$} to output (❤️ to @MajoroMask for request, added by @Midnighter, @sofstam, @jfy133) \#368 Add the ability to ignore profile errors caused by empty profiles and other validation errors when merging multiple profiles using TAXPASTA (added by @Midnighter and @LilyAnderssonLee) {$<$}code{$>$}Fixed{$<$}/code{$>$} \#271 Improved standardised table generation documentation for mOTUs manual database download tutorial (♥ to @prototaxites for reporting, fix by @jfy133) \#269 Reduced output files in AWS full test output due to very large files (fix by @jfy133) \#270 Fixed warning for host removal index parameter, and improved index checks (♥ to @prototaxites for reporting, fix by @jfy133) \#274 Substituted the samtools/bam2fq module with samtools/fastq module (fix by @sofstam) \#275 Replaced function used for error reporting to more Nextflow friendly method (fix by @jfy133) \#285 Fixed overly large log files in Kraken2 output (♥ to @prototaxites for reporting, fix by @Midnighter \&amp; @jfy133) \#286 Runtime optimisation of MultiQC step via improved log file processing (fix by @Midnighter \&amp; @jfy133) \#289 Pipeline updated to nf-core template 2.8 (fix by @Midnighter \&amp; @jfy133) \#290 Minor database input documentation improvements (♥ to @alneberg for reporting, fix by @jfy133) \#305 Fix docker/podman registry definition for tower compatibility (fix by @adamrtalbot, @jfy133) \#304 Correct mistake in kaiju2table documentation, only single rank can be supplied (♥ to @artur-matysik for reporting, fix by @jfy133) \#307 Fix databases being sometimes associated with the wrong tool (e.g. Kaiju) (fix by @jfy133, @Midnighter and @LilyAnderssonLee) \#313 Fix pipeline not providing error when database sheet does not have a header (♥ to @noah472 for reporting, fix by @jfy133) \#330 Added better tagging to allow disambiguation of Kraken2 steps of Kraken2 vs Bracken (♥ to @MajoroMask for requesting, added by @jfy133) \#334 Increase the memory of the FALCO process to 4GB (fix by @LilyAnderssonLee) \#332 Improved meta map stability for more robust pipeline resuming (fix by @jfy133) \#338 Fixed wrong file 'out' file going to {$<$}code{$>$}centrifuge kreport{$<$}/code{$>$} module (♥ to @LilyAnderssonLee for reporting, fix by @jfy133) \#342 Fixed docs/usage to correctly list the required database files for Bracken and tips to obtain Kraken2 databases (fix by @husensofteng) \#350 Reorganize the CI tests into separate profiles in preparation for implementation of nf-test (fix by @LilyAnderssonLee) \#364 Add autoMounts to apptainer profile in nextflow.config (♥ to @hkaspersento for reporting, fix by @LilyAnderssonLee) \#372 Update modules to use quay.io nf-core mirrored containers (♥ to @maxulysse for pointing out, fix by @LilyAnderssonLee and @jfy133) {$<$}code{$>$}Dependencies{$<$}/code{$>$} Tool Previous version New version MultiQC 1.13 1.15 TAXPASTA 0.2.3 0.6.0 MetaPhlAn 3.0.12 4.0.6 fastp 0.23.2 0.23.4 samtools 1.16.1 1.17 {$<$}code{$>$}Deprecated{$<$}/code{$>$} \#338 Updated Centrifuge module to not generate (undocumented) SAM alignments by default if --save\_centrifuge\_reads supplied, due to a Centrifuge bug modifying profile header. SAM alignments can still be generated if {$<$}code{$>$}--out-fmt{$<$}/code{$>$} supplied in {$<$}code{$>$}database.csv{$<$}/code{$>$} (♥ to @LilyAnderssonLee for reporting, fix by @jfy133)}
}
