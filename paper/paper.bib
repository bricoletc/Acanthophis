@article{beber23_taxpastataxonomic,
  title = {{{TAXPASTA}}: {{TAXonomic Profile Aggregation}} and {{STAndardisation}}},
  shorttitle = {{{TAXPASTA}}},
  author = {Beber, Moritz E. and Borry, Maxime and Stamouli, Sofia and Yates, James A. Fellows},
  year = {2023},
  month = jul,
  journal = {Journal of Open Source Software},
  volume = {8},
  number = {87},
  pages = {5627},
  issn = {2475-9066},
  doi = {10.21105/joss.05627},
  urldate = {2023-10-04},
  abstract = {Beber et al., (2023). TAXPASTA: TAXonomic Profile Aggregation and STAndardisation. Journal of Open Source Software, 8(87), 5627, https://doi.org/10.21105/joss.05627},
  langid = {english},
  file = {/home/kevin/work/bibliography/pdfs/beber23_taxpastataxonomic__journal_of_open_source_software__taxpasta.pdf}
}

@article{buchfink15_fastsensitive,
  title = {Fast and Sensitive Protein Alignment Using {{DIAMOND}}},
  author = {Buchfink, Benjamin and Xie, Chao and Huson, Daniel H.},
  year = {2015},
  month = jan,
  journal = {Nature Methods},
  volume = {12},
  number = {1},
  pages = {59--60},
  issn = {1548-7091},
  doi = {10.1038/nmeth.3176},
  urldate = {2016-07-13},
  abstract = {The alignment of sequencing reads against a protein reference database is a major computational bottleneck in metagenomics and data-intensive evolutionary projects. Although recent tools offer improved performance over the gold standard BLASTX, they exhibit only a modest speedup or low sensitivity. We introduce DIAMOND, an open-source algorithm based on double indexing that is 20,000 times faster than BLASTX on short reads and has a similar degree of sensitivity.},
  copyright = {\textcopyright{} 2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  keywords = {Software},
  file = {/home/kevin/work/bibliography/pdfs/buchfink15_fast__nature_methods__fast_and_sensitive_protein_alignment_using_diamond.pdf}
}

@article{danecek21_twelveyears,
  title = {Twelve Years of {{SAMtools}} and {{BCFtools}}},
  author = {Danecek, Petr and Bonfield, James K. and Liddle, Jennifer and Marshall, John and Ohan, Valeriu and Pollard, Martin O. and Whitwham, Andrew and Keane, Thomas and McCarthy, Shane A. and Davies, Robert M. and Li, Heng},
  year = {2021},
  month = feb,
  journal = {GigaScience},
  volume = {10},
  number = {2},
  pages = {giab008},
  issn = {2047-217X},
  doi = {10.1093/gigascience/giab008},
  abstract = {BACKGROUND: SAMtools and BCFtools are widely used programs for processing and analysing high-throughput sequencing data. They include tools for file format conversion and manipulation, sorting, querying, statistics, variant calling, and effect analysis amongst other methods. FINDINGS: The first version appeared online 12 years ago and has been maintained and further developed ever since, with many new features and improvements added over the years. The SAMtools and BCFtools packages represent a unique collection of tools that have been used in numerous other software projects and countless genomic pipelines. CONCLUSION: Both SAMtools and BCFtools are freely available on GitHub under the permissive MIT licence, free for both non-commercial and commercial use. Both packages have been installed {$>$}1 million times via Bioconda. The source code and documentation are available from https://www.htslib.org.},
  langid = {english},
  pmcid = {PMC7931819},
  pmid = {33590861},
  keywords = {bcftools,data analysis,Genome,Genomics,High-Throughput Nucleotide Sequencing,high-throughput sequencing,next generation sequencing,samtools,Software,variant calling},
  file = {/home/kevin/work/bibliography/pdfs/danecek21_twelveyears__gigascience__twelve_years_of_samtools_and_bcftools.pdf}
}

@article{ewels16_multiqcsummarize,
  title = {{{MultiQC}}: Summarize Analysis Results for Multiple Tools and Samples in a Single Report},
  shorttitle = {{{MultiQC}}},
  author = {Ewels, Philip and Magnusson, M{\aa}ns and Lundin, Sverker and K{\"a}ller, Max},
  year = {2016},
  month = oct,
  journal = {Bioinformatics (Oxford, England)},
  volume = {32},
  number = {19},
  pages = {3047--3048},
  issn = {1367-4811},
  doi = {10.1093/bioinformatics/btw354},
  abstract = {MOTIVATION: Fast and accurate quality control is essential for studies involving next-generation sequencing data. Whilst numerous tools exist to quantify QC metrics, there is no common approach to flexibly integrate these across tools and large sample sets. Assessing analysis results across an entire project can be time consuming and error prone; batch effects and outlier samples can easily be missed in the early stages of analysis. RESULTS: We present MultiQC, a tool to create a single report visualising output from multiple tools across many samples, enabling global trends and biases to be quickly identified. MultiQC can plot data from many common bioinformatics tools and is built to allow easy extension and customization. AVAILABILITY AND IMPLEMENTATION: MultiQC is available with an GNU GPLv3 license on GitHub, the Python Package Index and Bioconda. Documentation and example reports are available at http://multiqc.info CONTACT: phil.ewels@scilifelab.se.},
  langid = {english},
  pmcid = {PMC5039924},
  pmid = {27312411},
  keywords = {Computational Biology,High-Throughput Nucleotide Sequencing,Quality Control,Software},
  file = {/home/kevin/work/bibliography/pdfs/ewels16_multiqcsummarize__bioinformatics_(oxford,_england)__multiqc.pdf;/home/kevin/work/bibliography/zotdir/storage/DPTB57AL/Ewels et al. - 2016 - MultiQC summarize analysis results for multiple t.pdf}
}

@article{kim16_centrifugerapid,
  title = {Centrifuge: Rapid and Sensitive Classification of Metagenomic Sequences},
  shorttitle = {Centrifuge},
  author = {Kim, Daehwan and Song, Li and Breitwieser, Florian P. and Salzberg, Steven L.},
  year = {2016},
  month = oct,
  journal = {Genome Research},
  publisher = {{Cold Spring Harbor Lab}},
  issn = {1088-9051, 1549-5469},
  doi = {10.1101/gr.210641.116},
  urldate = {2023-10-04},
  abstract = {Centrifuge is a novel microbial classification engine that enables rapid, accurate, and sensitive labeling of reads and quantification of species on desktop computers. The system uses an indexing scheme based on the Burrows-Wheeler transform (BWT) and the Ferragina-Manzini (FM) index, optimized specifically for the metagenomic classification problem. Centrifuge requires a relatively small index (4.2 GB for 4078 bacterial and 200 archaeal genomes) and classifies sequences at very high speed, allowing it to process the millions of reads from a typical high-throughput DNA sequencing run within a few minutes. Together, these advances enable timely and accurate analysis of large metagenomics data sets on conventional desktop computers. Because of its space-optimized indexing schemes, Centrifuge also makes it possible to index the entire NCBI nonredundant nucleotide sequence database (a total of 109 billion bases) with an index size of 69 GB, in contrast to k-mer-based indexing schemes, which require far more extensive space.},
  langid = {english},
  pmid = {27852649},
  file = {/home/kevin/work/bibliography/pdfs/kim16_centrifugerapid__genome_research__centrifuge.pdf;/home/kevin/work/bibliography/zotdir/storage/NJ7R4HAT/Kim et al. - 2016 - Centrifuge rapid and sensitive classification of .pdf}
}

@article{koster12_snakemakescalable,
  title = {Snakemake --- a Scalable Bioinformatics Workflow Engine},
  author = {K{\"o}ster, Johannes and Rahmann, Sven},
  year = {2012},
  month = jan,
  journal = {Bioinformatics},
  volume = {28},
  number = {19},
  pages = {2520--2522},
  issn = {1367-4803, 1460-2059},
  doi = {10.1093/bioinformatics/bts480},
  urldate = {2016-03-30},
  abstract = {Summary: Snakemake is a workflow engine that provides a readable Python-based workflow definition language and a powerful execution environment that scales from single-core workstations to compute clusters without modifying the workflow. It is the first system to support the use of automatically inferred multiple named wildcards (or variables) in input and output filenames. Availability: http://snakemake.googlecode.com. Contact: johannes.koester@uni-due.de},
  langid = {english},
  pmid = {22908215},
  file = {/home/kevin/work/bibliography/pdfs/koster12_snakemake__bioinformatics__snakemake_---_a_scalable_bioinformatics_workflow_engine.pdf}
}

@article{li09_sequencealignment,
  title = {The {{Sequence Alignment}}/{{Map}} Format and {{SAMtools}}},
  author = {Li, Heng and Handsaker, Bob and Wysoker, Alec and Fennell, Tim and Ruan, Jue and Homer, Nils and Marth, Gabor and Abecasis, Goncalo and Durbin, Richard and {1000 Genome Project Data Processing Subgroup}},
  year = {2009},
  month = aug,
  journal = {Bioinformatics (Oxford, England)},
  volume = {25},
  number = {16},
  pages = {2078--2079},
  issn = {1367-4811},
  doi = {10.1093/bioinformatics/btp352},
  abstract = {SUMMARY: The Sequence Alignment/Map (SAM) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms. It is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 Genomes Project are released. SAMtools implements various utilities for post-processing alignments in the SAM format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments. AVAILABILITY: http://samtools.sourceforge.net.},
  langid = {english},
  pmcid = {PMC2723002},
  pmid = {19505943},
  keywords = {Algorithms,Base Sequence,Computational Biology,Genome,Genomics,Molecular Sequence Data,Sequence Alignment,{Sequence Analysis, DNA},Software},
  file = {/home/kevin/work/bibliography/pdfs/li09_sequencealignment__bioinformatics_(oxford,_england)__the_sequence_alignment-map_format_and_samtools.pdf;/home/kevin/work/bibliography/zotdir/storage/XV7LSKI4/Li et al. - 2009 - The Sequence AlignmentMap format and SAMtools.pdf}
}

@article{li11_statisticalframework,
  title = {A Statistical Framework for {{SNP}} Calling, Mutation Discovery, Association Mapping and Population Genetical Parameter Estimation from Sequencing Data},
  author = {Li, Heng},
  year = {2011},
  month = nov,
  journal = {Bioinformatics},
  volume = {27},
  number = {21},
  pages = {2987--2993},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btr509},
  urldate = {2017-05-30},
  abstract = {Motivation: Most existing methods for DNA sequence analysis rely on accurate sequences or genotypes. However, in applications of the next-generation sequencing (NGS), accurate genotypes may not be easily obtained (e.g. multi-sample low-coverage sequencing or somatic mutation discovery). These applications press for the development of new methods for analyzing sequence data with uncertainty., Results: We present a statistical framework for calling SNPs, discovering somatic mutations, inferring population genetical parameters and performing association tests directly based on sequencing data without explicit genotyping or linkage-based imputation. On real data, we demonstrate that our method achieves comparable accuracy to alternative methods for estimating site allele count, for inferring allele frequency spectrum and for association mapping. We also highlight the necessity of using symmetric datasets for finding somatic mutations and confirm that for discovering rare events, mismapping is frequently the leading source of errors., Availability: http://samtools.sourceforge.net, Contact: hengli@broadinstitute.org},
  pmcid = {PMC3198575},
  pmid = {21903627},
  file = {/home/kevin/work/bibliography/pdfs/li11_statistical__bioinformatics__a_statistical_framework_for_snp_calling,_mutation_discovery,_association.pdf}
}

@article{li13_aligningsequence,
  title = {Aligning Sequence Reads, Clone Sequences and Assembly Contigs with {{BWA-MEM}}},
  author = {Li, Heng},
  year = {2013},
  month = mar,
  urldate = {2019-01-02},
  abstract = {Summary: BWA-MEM is a new alignment algorithm for aligning sequence reads or long query sequences against a large reference genome such as human. It automatically chooses between local and end-to-end alignments, supports paired-end reads and performs chimeric alignment. The algorithm is robust to sequencing errors and applicable to a wide range of sequence lengths from 70bp to a few megabases. For mapping 100bp sequences, BWA-MEM shows better performance than several state-of-art read aligners to date.   Availability and implementation: BWA-MEM is implemented as a component of BWA, which is available at http://github.com/lh3/bwa.   Contact: hengli@broadinstitute.org},
  langid = {english},
  file = {/home/kevin/work/bibliography/pdfs/li13_aligning____aligning_sequence_reads,_clone_sequences_and_assembly_contigs_with_bwa-mem.pdf}
}

@article{li18_minimap2pairwise,
  title = {Minimap2: Pairwise Alignment for Nucleotide Sequences},
  shorttitle = {Minimap2},
  author = {Li, Heng},
  editor = {Birol, Inanc},
  year = {2018},
  month = sep,
  journal = {Bioinformatics},
  volume = {34},
  number = {18},
  pages = {3094--3100},
  issn = {1367-4803, 1367-4811},
  doi = {10.1093/bioinformatics/bty191},
  urldate = {2023-10-04},
  abstract = {Abstract                            Motivation               Recent advances in sequencing technologies promise ultra-long reads of {$\sim$}100 kb in average, full-length mRNA or cDNA reads in high throughput and genomic contigs over 100 Mb in length. Existing alignment programs are unable or inefficient to process such data at scale, which presses for the development of new alignment algorithms.                                         Results               Minimap2 is a general-purpose alignment program to map DNA or long mRNA sequences against a large reference database. It works with accurate short reads of {$\geq$}100\,bp in length, {$\geq$}1\,kb genomic reads at error rate {$\sim$}15\%, full-length noisy Direct RNA or cDNA reads and assembly contigs or closely related full chromosomes of hundreds of megabases in length. Minimap2 does split-read alignment, employs concave gap cost for long insertions and deletions and introduces new heuristics to reduce spurious alignments. It is 3\textendash 4 times as fast as mainstream short-read mappers at comparable accuracy, and is {$\geq$}30 times faster than long-read genomic or cDNA mappers at higher accuracy, surpassing most aligners specialized in one type of alignment.                                         Availability and implementation               https://github.com/lh3/minimap2                                         Supplementary information               Supplementary data are available at Bioinformatics online.},
  langid = {english},
  file = {/home/kevin/work/bibliography/pdfs/li18_minimap2pairwise__bioinformatics__minimap2.pdf}
}

@article{li21_newstrategies,
  title = {New Strategies to Improve Minimap2 Alignment Accuracy},
  author = {Li, Heng},
  editor = {Alkan, Can},
  year = {2021},
  month = dec,
  journal = {Bioinformatics},
  volume = {37},
  number = {23},
  pages = {4572--4574},
  issn = {1367-4803, 1367-4811},
  doi = {10.1093/bioinformatics/btab705},
  urldate = {2023-10-04},
  abstract = {Abstract                            Summary               We present several recent improvements to minimap2, a versatile pairwise aligner for nucleotide sequences. Now minimap2 v2.22 can more accurately map long reads to highly repetitive regions and align through insertions or deletions up to 100\,kb by default, addressing major weakness in minimap2 v2.18 or earlier.                                         Availability and implementation               https://github.com/lh3/minimap2.},
  langid = {english},
  file = {/home/kevin/work/bibliography/pdfs/li21_newstrategies__bioinformatics__new_strategies_to_improve_minimap2_alignment_accuracy.pdf}
}

@article{lindgreen12_adapterremoval,
  title = {{{AdapterRemoval}}: Easy Cleaning of next-Generation Sequencing Reads},
  shorttitle = {{{AdapterRemoval}}},
  author = {Lindgreen, Stinus},
  year = {2012},
  journal = {BMC Research Notes},
  volume = {5},
  pages = {337},
  issn = {1756-0500},
  doi = {10.1186/1756-0500-5-337},
  urldate = {2017-02-12},
  abstract = {With the advent of next-generation sequencing there is an increased demand for tools to pre-process and handle the vast amounts of data generated. One recurring problem is adapter contamination in the reads, i.e. the partial or complete sequencing of adapter sequences. These adapter sequences have to be removed as they can hinder correct mapping of the reads and influence SNP calling and other downstream analyses.},
  file = {/home/kevin/work/bibliography/pdfs/lindgreen12_adapterremoval__bmc_research_notes__adapterremoval.pdf}
}

@article{lu17_brackenestimating,
  title = {Bracken: Estimating Species Abundance in Metagenomics Data},
  shorttitle = {Bracken},
  author = {Lu, Jennifer and Breitwieser, Florian P. and Thielen, Peter and Salzberg, Steven L.},
  year = {2017},
  month = jan,
  journal = {PeerJ Computer Science},
  volume = {3},
  pages = {e104},
  issn = {2376-5992},
  doi = {10.7717/peerj-cs.104},
  urldate = {2017-08-08},
  abstract = {Metagenomic experiments attempt to characterize microbial communities using high-throughput DNA sequencing. Identification of the microorganisms in a sample provides information about the genetic profile, population structure, and role of microorganisms within an environment. Until recently, most metagenomics studies focused on high-level characterization at the level of phyla, or alternatively sequenced the 16S ribosomal RNA gene that is present in bacterial species. As the cost of sequencing has fallen, though, metagenomics experiments have increasingly used unbiased shotgun sequencing to capture all the organisms in a sample. This approach requires a method for estimating abundance directly from the raw read data. Here we describe a fast, accurate new method that computes the abundance at the species level using the reads collected in a metagenomics experiment. Bracken (Bayesian Reestimation of Abundance after Classification with KrakEN) uses the taxonomic assignments made by Kraken, a very fast read-level classifier, along with information about the genomes themselves to estimate abundance at the species level, the genus level, or above. We demonstrate that Bracken can produce accurate species- and genus-level abundance estimates even when a sample contains multiple near-identical species.},
  langid = {english},
  file = {/home/kevin/work/bibliography/pdfs/lu17_bracken__peerj_computer_science__bracken.pdf}
}

@article{menzel16_fastsensitive,
  title = {Fast and Sensitive Taxonomic Classification for Metagenomics with {{Kaiju}}},
  author = {Menzel, Peter and Ng, Kim Lee and Krogh, Anders},
  year = {2016},
  month = apr,
  journal = {Nature Communications},
  volume = {7},
  pages = {11257},
  issn = {2041-1723},
  doi = {10.1038/ncomms11257},
  urldate = {2016-09-27},
  keywords = {Bioinformatics,Biological sciences,Genetics},
  file = {/home/kevin/work/bibliography/pdfs/menzel16_fast__nature_communications__fast_and_sensitive_taxonomic_classification_for_metagenomics_with_kaiju.pdf}
}

@article{moran15_hologenomeconcept,
  title = {The {{Hologenome Concept}}: {{Helpful}} or {{Hollow}}?},
  shorttitle = {The {{Hologenome Concept}}},
  author = {Moran, Nancy A. and Sloan, Daniel B.},
  year = {2015},
  month = dec,
  journal = {PLoS Biol},
  volume = {13},
  number = {12},
  pages = {e1002311},
  doi = {10.1371/journal.pbio.1002311},
  urldate = {2015-12-09},
  abstract = {It is accepted that microbial symbionts are important to the biology of their hosts, but this essay asks what evidence is needed to determine whether symbionts and hosts have coevolved and whether they form higher units of evolutionary selection.},
  file = {/home/kevin/work/bibliography/pdfs/moran15_hologenome__plos_biol__the_hologenome_concept.pdf}
}

@article{schubert16_adapterremoval,
  title = {{{AdapterRemoval}} v2: Rapid Adapter Trimming, Identification, and Read Merging},
  shorttitle = {{{AdapterRemoval}} V2},
  author = {Schubert, Mikkel and Lindgreen, Stinus and Orlando, Ludovic},
  year = {2016},
  journal = {BMC Research Notes},
  volume = {9},
  pages = {88},
  issn = {1756-0500},
  doi = {10.1186/s13104-016-1900-2},
  urldate = {2016-06-07},
  abstract = {As high-throughput sequencing platforms produce longer and longer reads, sequences generated from short inserts, such as those obtained from fossil and degraded material, are increasingly expected to contain adapter sequences. Efficient adapter trimming algorithms are also needed to process the growing amount of data generated per sequencing run.},
  keywords = {Adapter identification,Adapter trimming,Data pre-processing,High-throughput sequencing,Sequence Alignment},
  file = {/home/kevin/work/bibliography/pdfs/schubert16_adapterremoval__bmc_research_notes__adapterremoval_v2.pdf}
}

@article{sedlazeck13_nextgenmapfast,
  title = {{{NextGenMap}}: Fast and Accurate Read Mapping in Highly Polymorphic Genomes},
  shorttitle = {{{NextGenMap}}},
  author = {Sedlazeck, Fritz J. and Rescheneder, Philipp and Von Haeseler, Arndt},
  year = {2013},
  month = nov,
  journal = {Bioinformatics},
  volume = {29},
  number = {21},
  pages = {2790--2791},
  issn = {1367-4803, 1367-4811},
  doi = {10.1093/bioinformatics/btt468},
  urldate = {2023-10-04},
  abstract = {Abstract             Summary: When choosing a read mapper, one faces the trade off between speed and the ability to map reads in highly polymorphic regions. Here, we report NextGenMap, a fast and accurate read mapper, which reduces this dilemma. NextGenMap aligns reads reliably to a reference genome even when the sequence difference between target and reference genome is large, i.e. highly polymorphic genome. At the same time, NextGenMap outperforms current mapping methods with respect to runtime and to the number of correctly mapped reads. NextGenMap efficiently uses the available hardware by exploiting multi-core CPUs as well as graphic cards (GPUs), if available. In addition, NextGenMap handles automatically any read data independent of read length and sequencing technology.             Availability: NextGenMap source code and documentation are available at: http://cibiv.github.io/NextGenMap/             Contact: fritz.sedlazeck@univie.ac.at             Supplementary information: ~Supplementary data are available at Bioinformatics online.},
  langid = {english},
  file = {/home/kevin/work/bibliography/pdfs/sedlazeck13_nextgenmapfast__bioinformatics__nextgenmap.pdf;/home/kevin/work/bibliography/zotdir/storage/CPW9E3RZ/Sedlazeck et al. - 2013 - NextGenMap fast and accurate read mapping in high.pdf}
}

@misc{weigel20_pathocomproposal,
  title = {{{PATHOCOM}} Proposal},
  author = {Weigel, Detlef and Bergelson, Joy and Roux, Fabrice},
  year = {2020},
  month = nov,
  publisher = {{figshare}},
  doi = {10.6084/m9.figshare.13174337.v1},
  urldate = {2023-10-04},
  abstract = {PATHOCOM is a project proposal submitted by Detlef Weigel, Fabrice Roux and Joy Bergelson to the ERC Synergy Grants (ERC-SyG) 2020 call},
  archiveprefix = {figshare},
  langid = {english},
  file = {/home/kevin/work/bibliography/pdfs/weigel20_pathocomproposal____pathocom_proposal.pdf}
}
